{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.07</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y     x0     x1     x2      x3      x4      x5    x6  x7\n",
       "0  1  0.455  0.365  0.095  0.5140  0.2245  0.1010  0.15  15\n",
       "1  1  0.350  0.265  0.090  0.2255  0.0995  0.0485  0.07   7"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('abalone.txt', names=['y', 'x0', 'x1', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7'], sep='\\t')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4177, 9), (4177,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.iloc[:, 1:].values\n",
    "Y = df.iloc[:, 0].values\n",
    "\n",
    "X = np.concatenate([np.ones((X.shape[0], 1)), X], axis=1)\n",
    "\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 梯度下降"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regression:\n",
    "    \n",
    "    def __init__(self, alpha=0.01, lr=0.01, max_iter=100):\n",
    "        self._alpha = alpha\n",
    "        self._lr = lr\n",
    "        self._max_iter = max_iter\n",
    "        \n",
    "    def _cost(self, Y, Y_pre):\n",
    "        Y = Y.reshape((-1, 1))\n",
    "        Y_pre = Y_pre.reshape((-1, 1))\n",
    "        return np.mean(np.square(Y_pre - Y) + self._alpha * (self._weights.T @ self._weights)) / 2\n",
    "        \n",
    "    def _foreward(self, X):\n",
    "        m, n = X.shape\n",
    "        Y_pre = X @ self._weights\n",
    "        cost = self._cost(Y, Y_pre)\n",
    "        \n",
    "        return cost, Y_pre\n",
    "    \n",
    "    def _backward(self, X, Y, Y_pre):\n",
    "        Y = Y.reshape((-1, 1))\n",
    "        Y_pre = Y_pre.reshape((-1, 1))\n",
    "        m = X.shape[0]\n",
    "        \n",
    "        weights_diff =  X.T @ (Y_pre - Y) / m  + (self._alpha / m) * self._weights\n",
    "        \n",
    "        return weights_diff\n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        n = X.shape[1]\n",
    "        self._weights = np.random.randn(n, 1)\n",
    "        \n",
    "        for step in range(self._max_iter):\n",
    "            cost, Y_pre = self._foreward(X)\n",
    "            weights_diff = self._backward(X, Y, Y_pre)\n",
    "            \n",
    "            self._weights -= self._lr * weights_diff\n",
    "            \n",
    "            print('step:{0} -- cost:{1}'.format(step, cost))\n",
    "            \n",
    "    def predict(self, X):\n",
    "        return X @ self._weights\n",
    "        \n",
    "    def mse(self, Y, Y_pre):\n",
    "        return np.mean(np.square(Y - Y_pre))\n",
    "    \n",
    "    def r2(self, Y, Y_pre):\n",
    "        Y = Y.reshape((-1, 1))\n",
    "        Y_pre = Y_pre.reshape((-1, 1))\n",
    "        return 1 - (np.sum(np.square(Y - Y_pre)) / np.sum(np.square(Y - np.mean(Y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StandardScaler:\n",
    "    \n",
    "    def fit(self, X):\n",
    "        self._mean = np.mean(X)\n",
    "        self._std = np.std(X)\n",
    "        \n",
    "    def transform(self, X):\n",
    "        return (X - self._mean) / self._std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X_std = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:0 -- cost:9.255959581519033\n",
      "step:1 -- cost:0.5117118090934903\n",
      "step:2 -- cost:0.38934712263041193\n",
      "step:3 -- cost:0.3869791119561498\n",
      "step:4 -- cost:0.3863048267767523\n",
      "step:5 -- cost:0.3856758934534759\n",
      "step:6 -- cost:0.3850684561133559\n",
      "step:7 -- cost:0.38448145749761636\n",
      "step:8 -- cost:0.3839142014689742\n",
      "step:9 -- cost:0.3833660221483733\n",
      "step:10 -- cost:0.38283627643314067\n",
      "step:11 -- cost:0.38232434290170964\n",
      "step:12 -- cost:0.38182962105171975\n",
      "step:13 -- cost:0.38135153059276516\n",
      "step:14 -- cost:0.3808895107662579\n",
      "step:15 -- cost:0.38044301968854605\n",
      "step:16 -- cost:0.3800115337161586\n",
      "step:17 -- cost:0.37959454683239197\n",
      "step:18 -- cost:0.37919157005451665\n",
      "step:19 -- cost:0.3788021308609108\n",
      "step:20 -- cost:0.37842577263744936\n",
      "step:21 -- cost:0.378062054142504\n",
      "step:22 -- cost:0.3777105489899261\n",
      "step:23 -- cost:0.37737084514941105\n",
      "step:24 -- cost:0.3770425444636561\n",
      "step:25 -- cost:0.37672526218175156\n",
      "step:26 -- cost:0.37641862650825614\n",
      "step:27 -- cost:0.3761222781674317\n",
      "step:28 -- cost:0.3758358699821274\n",
      "step:29 -- cost:0.37555906646681964\n",
      "step:30 -- cost:0.37529154343433396\n",
      "step:31 -- cost:0.3750329876157879\n",
      "step:32 -- cost:0.3747830962933107\n",
      "step:33 -- cost:0.3745415769451106\n",
      "step:34 -- cost:0.37430814690247444\n",
      "step:35 -- cost:0.37408253301829925\n",
      "step:36 -- cost:0.37386447134676704\n",
      "step:37 -- cost:0.3736537068337897\n",
      "step:38 -- cost:0.3734499930178606\n",
      "step:39 -- cost:0.3732530917409645\n",
      "step:40 -- cost:0.373062772869207\n",
      "step:41 -- cost:0.37287881402283596\n",
      "step:42 -- cost:0.37270100031534165\n",
      "step:43 -- cost:0.37252912410132816\n",
      "step:44 -- cost:0.3723629847328617\n",
      "step:45 -- cost:0.3722023883240128\n",
      "step:46 -- cost:0.3720471475233138\n",
      "step:47 -- cost:0.3718970812938685\n",
      "step:48 -- cost:0.3717520147008549\n",
      "step:49 -- cost:0.37161177870617385\n",
      "step:50 -- cost:0.3714762099700017\n",
      "step:51 -- cost:0.3713451506590175\n",
      "step:52 -- cost:0.3712184482610773\n",
      "step:53 -- cost:0.37109595540612156\n",
      "step:54 -- cost:0.3709775296931045\n",
      "step:55 -- cost:0.37086303352274363\n",
      "step:56 -- cost:0.3707523339358935\n",
      "step:57 -- cost:0.3706453024573553\n",
      "step:58 -- cost:0.3705418149449384\n",
      "step:59 -- cost:0.37044175144359853\n",
      "step:60 -- cost:0.3703449960444814\n",
      "step:61 -- cost:0.3702514367487065\n",
      "step:62 -- cost:0.3701609653357323\n",
      "step:63 -- cost:0.3700734772361487\n",
      "step:64 -- cost:0.36998887140874825\n",
      "step:65 -- cost:0.3699070502217311\n",
      "step:66 -- cost:0.36982791933790593\n",
      "step:67 -- cost:0.36975138760375276\n",
      "step:68 -- cost:0.369677366942216\n",
      "step:69 -- cost:0.3696057722491044\n",
      "step:70 -- cost:0.3695365212929759\n",
      "step:71 -- cost:0.36946953461838905\n",
      "step:72 -- cost:0.3694047354524106\n",
      "step:73 -- cost:0.3693420496142659\n",
      "step:74 -- cost:0.36928140542803073\n",
      "step:75 -- cost:0.36922273363825914\n",
      "step:76 -- cost:0.3691659673284493\n",
      "step:77 -- cost:0.3691110418422535\n",
      "step:78 -- cost:0.36905789470733774\n",
      "step:79 -- cost:0.36900646556180355\n",
      "step:80 -- cost:0.36895669608308507\n",
      "step:81 -- cost:0.3689085299192382\n",
      "step:82 -- cost:0.3688619126225425\n",
      "step:83 -- cost:0.3688167915853355\n",
      "step:84 -- cost:0.36877311597800777\n",
      "step:85 -- cost:0.3687308366890831\n",
      "step:86 -- cost:0.36868990626731557\n",
      "step:87 -- cost:0.36865027886573504\n",
      "step:88 -- cost:0.36861191018757494\n",
      "step:89 -- cost:0.3685747574340205\n",
      "step:90 -- cost:0.3685387792537149\n",
      "step:91 -- cost:0.3685039356939651\n",
      "step:92 -- cost:0.36847018815358923\n",
      "step:93 -- cost:0.36843749933735137\n",
      "step:94 -- cost:0.36840583321192993\n",
      "step:95 -- cost:0.3683751549633679\n",
      "step:96 -- cost:0.3683454309559554\n",
      "step:97 -- cost:0.3683166286924956\n",
      "step:98 -- cost:0.36828871677590935\n",
      "step:99 -- cost:0.3682616648721309\n"
     ]
    }
   ],
   "source": [
    "regression = Regression(alpha=0.01, lr=0.1, max_iter=100)\n",
    "regression.fit(X_std, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pre = regression.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.6727829153398548, 1.7944146501271649)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression.r2(Y, Y_pre), regression.mse(Y, Y_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
