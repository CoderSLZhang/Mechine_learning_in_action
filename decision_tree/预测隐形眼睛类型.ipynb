{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    \n",
    "    def _calShannonEnt(self, Y):\n",
    "        totalCount = len(Y)\n",
    "        counter = Counter(Y)\n",
    "        \n",
    "        shannonEnt = 0.0\n",
    "        \n",
    "        for key in counter.keys():\n",
    "            prob = counter[key] / totalCount\n",
    "            shannonEnt -= prob * np.log2(prob)\n",
    "            \n",
    "        return shannonEnt\n",
    "    \n",
    "    def _splitDataset(self, X, Y, index, value):\n",
    "        totalCount = len(X)\n",
    "        \n",
    "        splitX = []\n",
    "        splitY = []\n",
    "        \n",
    "        for i in range(totalCount):\n",
    "            x = X[i]\n",
    "            y = Y[i]\n",
    "            \n",
    "            if x[index] == value:\n",
    "                new_x = np.concatenate([x[:index], x[index + 1:]])\n",
    "                splitX.append(new_x)\n",
    "                splitY.append(y)\n",
    "                \n",
    "        return np.stack(splitX), np.stack(splitY)\n",
    "    \n",
    "    def _chooseBestFeature(self, X, Y):\n",
    "        baseEnt = self._calShannonEnt(Y)\n",
    "        bestInfoGain = 0.0\n",
    "        bestFeature = -1\n",
    "        featureCount = len(X[0])\n",
    "        totalCount = len(Y)\n",
    "        \n",
    "        for i in range(featureCount):\n",
    "            valueSet = set(X[:, i])\n",
    "            featureEnt = 0.0\n",
    "            \n",
    "            for value in valueSet:\n",
    "                _, splitY = self._splitDataset(X, Y, i, value)\n",
    "                ent = self._calShannonEnt(splitY)\n",
    "                \n",
    "                prob = len(splitY) / totalCount\n",
    "                featureEnt += prob * ent\n",
    "                \n",
    "            featureInfoGain = baseEnt - featureEnt\n",
    "            if featureInfoGain > bestInfoGain:\n",
    "                bestInfoGain = featureInfoGain\n",
    "                bestFeature = i\n",
    "                \n",
    "        return bestFeature\n",
    "    \n",
    "    def _majorityCount(self, Y):\n",
    "        return Counter(Y).most_common()[0][0]\n",
    "    \n",
    "    def _createTree(self, X, Y, featureNames):\n",
    "        counter = Counter(Y)\n",
    "        \n",
    "        if len(counter) == 1:\n",
    "            return Y[0]\n",
    "        \n",
    "        if len(featureNames) == 0:\n",
    "            return self._majorityCount(Y)\n",
    "        \n",
    "        bestFeatureIndex = self._chooseBestFeature(X, Y)\n",
    "        bestFeature = featureNames[bestFeatureIndex]\n",
    "        \n",
    "        tree = {bestFeature: {}}\n",
    "        \n",
    "        featureValueSet = set(X[:, bestFeatureIndex])\n",
    "        for value in featureValueSet:\n",
    "            splitX, splitY = self._splitDataset(X, Y, bestFeatureIndex, value)\n",
    "            \n",
    "            splitFeature = featureNames.copy()\n",
    "            splitFeature.remove(bestFeature)\n",
    "            \n",
    "            tree[bestFeature][value] = self._createTree(splitX, splitY, splitFeature)\n",
    "            \n",
    "        return tree\n",
    "    \n",
    "    def _treePredict(self, x, featureNames, tree):\n",
    "        bestFeature = list(tree.keys())[0]\n",
    "        bestIndex = featureNames.index(bestFeature)\n",
    "        \n",
    "        subTreeDict = tree[bestFeature]\n",
    "        subTree = subTreeDict[x[bestIndex]]\n",
    "        \n",
    "        if isinstance(subTree, dict):\n",
    "            label = self._treePredict(x, featureNames, subTree)\n",
    "        else:\n",
    "            label = subTree\n",
    "            \n",
    "        return label\n",
    "    \n",
    "    def _treeDepth(self, tree):\n",
    "        depth = 1\n",
    "        \n",
    "        subTreeDict = list(tree.values())[0]\n",
    "        \n",
    "        subDepths = []\n",
    "        for subTree in subTreeDict.values():                \n",
    "            if isinstance(subTree, dict):\n",
    "                subDepth = self._treeDepth(subTree)\n",
    "                subDepths.append(subDepth)\n",
    "                \n",
    "        if len(subDepths) > 0:\n",
    "            depth += max(subDepths)\n",
    "        \n",
    "        return depth\n",
    "    \n",
    "    def _leafsNum(self, tree):\n",
    "        leafsNum = 0\n",
    "        \n",
    "        subTreeDict = list(tree.values())[0]\n",
    "        \n",
    "        for subTree in subTreeDict.values():\n",
    "            if isinstance(subTree, dict):\n",
    "                leafsNum += self._leafsNum(subTree)\n",
    "            else:\n",
    "                leafsNum += 1\n",
    "                \n",
    "        return leafsNum\n",
    "    \n",
    "    def fit(self, X, Y, featureNames):\n",
    "        self._tree = self._createTree(X, Y, featureNames)\n",
    "    \n",
    "    def predict(self, X, featureNames):\n",
    "        Y = [self._treePredict(x, featureNames, self._tree) for x in X]\n",
    "        \n",
    "        return np.stack(Y)\n",
    "    \n",
    "    def save(self, path):\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(self._tree, f)\n",
    "            \n",
    "    def load(self, path):\n",
    "        with open(path, 'rb') as f:\n",
    "            pickle.load(f)\n",
    "            \n",
    "    def getTreeDepth(self):\n",
    "        return self._treeDepth(self._tree)\n",
    "    \n",
    "    def getLeafsNum(self):\n",
    "        return self._leafsNum(self._tree)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'lenses.txt'\n",
    "FEATURES = ['age', 'prescript', 'astigmatic', 'tearRate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataset(path):\n",
    "    with open(path) as f:\n",
    "        lines = f.readlines()\n",
    "        \n",
    "    dataset = [line.strip().split('\\t') for line in lines]\n",
    "    dataset = np.array(dataset)\n",
    "    \n",
    "    X = dataset[:, :-1]\n",
    "    Y = dataset[:, -1]\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24, 4), (24,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = createDataset(DATASET)\n",
    "\n",
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.fit(X, Y, FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['no lenses', 'soft', 'no lenses', 'hard', 'no lenses', 'soft',\n",
       "       'no lenses', 'hard', 'no lenses', 'soft', 'no lenses', 'hard',\n",
       "       'no lenses', 'soft', 'no lenses', 'no lenses', 'no lenses',\n",
       "       'no lenses', 'no lenses', 'hard', 'no lenses', 'soft', 'no lenses',\n",
       "       'no lenses'], dtype='<U9')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.predict(X, FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.save('decision_tree.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.load('decision_tree.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.getTreeDepth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.getLeafsNum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
