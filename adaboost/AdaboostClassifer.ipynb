{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaBoostClassifer:\n",
    "    \n",
    "    def __init__(self, max_estimators=50):\n",
    "        self._max_estimators = max_estimators\n",
    "        \n",
    "    def _stumClassify(self, X, featureIndex, threshVal, threshSymbol):\n",
    "        retList = np.ones((X.shape[0],))\n",
    "        \n",
    "        if threshSymbol == 'lt':\n",
    "            retList[X[:, featureIndex] <= threshVal] = -1\n",
    "        else:\n",
    "            retList[X[:, featureIndex] > threshVal] = -1\n",
    "            \n",
    "        return retList\n",
    "    \n",
    "    def _buildStump(self, X, Y, D):\n",
    "        m, n = X.shape\n",
    "        numSteps = 10\n",
    "        bestStump = {}\n",
    "        bestPredictions = np.zeros((m, 1))\n",
    "        minError = float('inf')\n",
    "        \n",
    "        for i in range(n):\n",
    "            rangeMin = X[:, i].min()\n",
    "            rangeMax = X[:, i].max()\n",
    "            stepSize = (rangeMax - rangeMin) / numSteps\n",
    "            \n",
    "            for j in range(-1, numSteps + 1):\n",
    "                for symbol in ['lt', 'gt']:\n",
    "                    threshVal = rangeMin + j * stepSize\n",
    "                    predictions = self._stumClassify(X, i, threshVal, symbol)\n",
    "                    \n",
    "                    errList = (predictions != Y).astype(np.int)\n",
    "                    weightError = np.dot(D, errList)\n",
    "                    \n",
    "#                     print('split: dim:{0}, thresh:{1}, thresh sybmol:{2}, weighted error is:{3}'.format(i, j, symbol, weightError))\n",
    "\n",
    "                    if weightError < minError:\n",
    "                        minError = weightError\n",
    "                        bestPredictions = predictions\n",
    "                        bestStump['dim'] = i\n",
    "                        bestStump['thresh'] = threshVal\n",
    "                        bestStump['symbol'] = symbol\n",
    "#                         print('weightError:', weightError)\n",
    "                        \n",
    "        return bestStump, minError, bestPredictions             \n",
    "    \n",
    "    def fit(self, X, Y):\n",
    "        weakClassList = []\n",
    "        m = X.shape[0]\n",
    "        D = np.ones((m,)) / m\n",
    "        predictions = np.zeros((m,))\n",
    "\n",
    "        for i in range(self._max_estimators):\n",
    "            bestStump, minError, bestPredictions = self._buildStump(X, Y, D)\n",
    "            alpha = float(0.5 * np.log((1.0 - minError) / max(minError, 1e-16)))\n",
    "            bestStump['alpha'] = alpha\n",
    "            weakClassList.append(bestStump)\n",
    "            \n",
    "#             print('min error: ', minError)\n",
    "#             print('alpha: ', alpha)\n",
    "\n",
    "            expon = -1 * Y * bestPredictions * alpha\n",
    "            D = D * np.exp(expon)\n",
    "            D = D / D.sum()\n",
    "            \n",
    "#             print('D: ', D)\n",
    "            \n",
    "            predictions += alpha * bestPredictions\n",
    "            \n",
    "            error = (np.sign(predictions) != Y).sum()\n",
    "            errorRate = error / m\n",
    "            \n",
    "#             print('sub claasifier errorRate: {0}'.format(errorRate))\n",
    "            \n",
    "            if errorRate == 0:\n",
    "                break\n",
    "                \n",
    "        self._weakClassList = weakClassList     \n",
    "        \n",
    "    def predict(self, X):\n",
    "        m = X.shape[0]\n",
    "        finalPredictions = np.zeros((m,))\n",
    "        \n",
    "        for index, subClassifer in enumerate(self._weakClassList):\n",
    "            subPredictions = self._stumClassify(X, \n",
    "                                                subClassifer['dim'],\n",
    "                                                subClassifer['thresh'],\n",
    "                                                subClassifer['symbol']\n",
    "                                               )\n",
    "            \n",
    "            finalPredictions += subClassifer['alpha'] * subPredictions\n",
    "            \n",
    "        return np.sign(finalPredictions)\n",
    "    \n",
    "    def accuracy(self, Y, predictions):\n",
    "        return np.mean(Y == predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(path):\n",
    "    X = []\n",
    "    Y = []\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            parts = [float(part) for part in line.split('\\t')]\n",
    "            X.append(parts[:-1])\n",
    "            Y.append(parts[-1])\n",
    "            \n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = loadData('./data/horseColicTraining2.txt')\n",
    "X_test, Y_test = loadData('./data/horseColicTest2.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((299, 21), (299,), (67, 21), (67,))"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaClassifer = AdaBoostClassifer(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaClassifer.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7910447761194029"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_test = adaClassifer.predict(X_test)\n",
    "adaClassifer.accuracy(prediction_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
